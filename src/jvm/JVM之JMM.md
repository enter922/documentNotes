## JMM内存模型

JMM 即 Java Memory Model，它定义了主存（共享内存）、工作内存（线程私有）抽象概念，底层对应着 CPU 寄存器、缓存、硬件内存、 CPU 指令优化等。

JMM 体现在以下几个方面

- **原子性** - 保证指令不会受到线程上下文切换的影响
- **可见性** - 保证指令不会受 cpu 缓存的影响
- **有序性** - 保证指令不会受 cpu 指令并行优化的影响



## 可见性

阅读之前先看一个退不出的循环

```java
public static boolean run = true;
    public static void main(String[] args) {
        Thread t1 = new Thread(() -> {
            while(run) {
            }
        }, "t1");

        t1.start();
		Thread.sleep(1000);
        log.info("t1 Stop");
        run = false;
    }
```

代码执行结果并没有和预想的一样停止运行输出`t1 Stop`

这是因为t1线程将主内存的run读取保存到了本地内存，当run改变前后，t1一直在本地内存读取run，导致主内存的改变对现场不可见

所以可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

**解决方法:**

- 对run添加volatile关键子修饰，volatile能解决可见性和有序性
- 他可以避免线程从自己的工作缓存中查找变量的值，必须到主存中获取它的值，线程操作 volatile 变量都是直接操作主存

> - 添加synchronized，但synchronized属于重量级操作



## 有序性

阅读之前先了解一下指令重排序

- 编译器和CPU为了提高指令的执行效率可能会进行指令重排序，将一个执行时间较短的代码放到执行时间较长的代码前执行，这使得代码的实际执行顺序可能不是按照我们所认为的顺序进行。
- 指令重排必须遵守as-if-serial语义，即：不管怎么重排序，程序的执行结果不能被改变。
- 指令重排主要发生在编译阶段和运行阶段。
- 指令重排序在单线程的情况下能提高一定运行速度，但在多线程情况下不然，会影响结果正确性。

- 指令重排简单来说，可以在程序结果不受影响的前提下，可以调整指令语句执行顺序。多线程下指令重排会影响正确性。

是否可以重排序:

```java
// 可以重排的例子 
int a = 10; 
int b = 20; 
System.out.println( a + b );//a 和 b 相互不影响
// 不能重排的例子 
int a = 10;
int b = a - 5;   //如果重排序那么 会使用a的默认值0减去5，结果错误为-5
```

有序性最终表述的现象是**CPU是否按照编写代码顺序执行依次执行指令**

**解决方法**

- 使用volatle修饰解决有序性
- 使用synchronized和Lock也可以保证有序性，因为它们的代码变成了同步代码块，自然不会有指令乱序问题。



### Volatile

volatile主要作用有**可见性**和**有序性**

强制将修改后的值刷新到主内存中来保持内存的可见性，让一个线程对共享变量的修改对另一个线程可见。

过 CPU内存屏障禁止编译器指令性重排来保证并发操作的有序性。

 Java 中，Java 并没有直接实现 CAS（Compare And Swap），CAS 相关的实现是通过 C++ 内联汇编的形式实现的。

**原子性**

* 起因：多线程下，不同线程的**指令发生了交错**导致的共享变量的读写混乱
* 解决：用悲观锁或乐观锁解决，volatile 并不能解决原子性

**可见性**

* 起因：由于**编译器优化、或缓存优化、或 CPU 指令重排序优化**导致的对共享变量所做的修改另外的线程看不到
* 解决：用 volatile 修饰共享变量，能够防止编译器等优化发生，让一个线程对共享变量的修改对另一个线程可见

**有序性**

* 起因：由于**编译器优化、或缓存优化、或 CPU 指令重排序优化**导致指令的实际执行顺序与编写顺序不一致
* 解决：用 volatile 修饰共享变量会在读、写共享变量时加入不同的屏障，阻止其他读写操作越过屏障，从而达到阻止重排序的效果
* 注意：
  * **volatile 变量写**加的屏障是阻止上方其它写操作越过屏障排到 **volatile 变量写**之下
  * **volatile 变量读**加的屏障是阻止下方其它读操作越过屏障排到 **volatile 变量读**之上
  * volatile 读写加入的屏障只能防止同一线程内的指令重排

> **要求**
>
> * 掌握线程安全要考虑的三个问题
> * 掌握 volatile 能解决哪些问题
>
> *注：在jdk5以前volatile存在但实际无效*



## **原子性** 

原子性操作指相应的操作是单一不可分割的操作。只能是全部成功或失败，不能是部分成功部分失败。

单线程环境下我们可以认为整个步骤都是原子性操作，但是在多线程环境下则不同，Java只保证了基本数据类型的变量和赋值操作才是原子性的（注：在32位的JDK环境下，对64位数据的读取不是原子性操作，如long、double）

**要想在多线程环境下保证原子性，则可以通过Lock、synchronized来确保。**volatile是无法保证复合操作的原子性。

因为synchronized和Lock能够保证任一时刻只有一个线程访问该代码块。



### Synchronized

- synchronized 是 Java 中的关键字，是jvm层级的，用 c++ 语言实现，是利用锁的机制来实现线程同步保障原子性，属于一种互斥锁，是悲观锁的体现。

- synchronized 可以用来给对象和方法或者代码块加锁，当它锁定一个方法或者代码块的时候，同一时刻最多只有一条线程执行这段代码，属于一种互斥锁，同时，synchronized 也具有可见性，但synchronized属于重量级操作，开销更大
- 除了volatile之外，**synchronized除了保证原子还可以保证可见性**，但synchronized属于重量级操作，开销更大

- 在`System.out.println()`中就是用了synchronized来保证字符输出的原子性和可见性，所以sout性能较低，推荐日志框架输出

- 在使用synchronized锁时可适当扩大区间，重复多次加锁消耗性能



## CAS

### 什么是CAS

CAS全称比较并交换，体现的是一种乐观锁的思想，也就是不加锁

上一次读取到的值和共享变量比较

依赖底层unsafe操作

获取共享变量时，为了保证该变量的可见性，需要使用 volatile 修饰。结合 CAS 和 Volatile 可以实现无锁并发，避免了切换带来的开销适用于竞争不激烈、多核 CPU的场景下

因为没有使用 synchronized，所以线程不会陷入阻塞，这是效率提升的因素之一，但如果竞争激烈，可以想到重试必然频警发生，反而效率会受影响

使用CAS过于繁琐，可使用jdk的原子实现



### CAS的缺点？

- 普通CAS只能维持最终一致性。

**举例：**

桌子上有1000元，在离开的时候，一人还钱100元，一个借钱100元。

在回来的时候，仍然是1000元，就好像没有人涉及这些金额，但实际中间被操作了。

**如何解决？**

对CAS添加版本号，即在离开的时候，每一个借钱和还钱的时候会在此留下标记：发微信说明



## Synchronized优化

### 概念

Synchronized属于的独占式的重量级锁，在同步代码块的时候，需要从内核态切换到内核态，频繁的程的挂起和唤醒，会消耗系统资源。从jdk1.6开始对Synchronized做了大幅度优化，用来减少锁竞争带来的上下文切换

阅读之前先解释一些名词:

- 自旋：自我重试，对重量锁的优化
- 锁重入：多次加锁
- 锁升级：偏向锁升级为轻量级锁再升级到重量级锁
- 锁膨胀：轻量级锁升级重量级锁
- 偏向锁：取消锁重入，但撤销偏向锁是重量级操作
- 锁粗化：将同一个对象多次加锁优化为一次
- 锁消除：做逃逸分析
- 重量级锁：轻量级的相对，传统锁
- 轻量级锁：“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的
- 读写分离：CopyOnWriteArrayList，只对写加锁



### 对象头

synchronized依赖于对象头的信息，故而先了解一下对象头

1. 在JDK 1.6的JVM中，对象实例在**堆内存**中被分为三部分：**对象头**、**实例数据**、**对齐填充**
2. 对象头的组成部分：**Mark Word**、**指向类的指针**、**数组长度**（可选，数组类型时才有
3. Mark Word记录了**对象**和**锁**有关的信息，在64位的JVM中，Mark Word为**64 bit**
4. 锁升级功能主要依赖于Mark Word中**锁标志位**和**是否偏向锁标志位**
5. synchronized同步锁的升级优化路径：**偏向锁**  > **轻量级锁** > **重量级锁**

> 八个字节就是8个bytes，计算机存储量的计量单位是字节，一个字节是2进制8位，八个字节等于 8*8=64 ， 即2进制64位。

![image-20230507190421335](images\image-20230507190421335.png)

### 优化

#### 轻量级锁

**什么是轻量级锁？**

- “轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的。但轻量级锁并不是用来代替重量级锁的。

如果一个对象虽然有多线程访问，但某个时间点多线程访问的时间是错开的（也就是没有竞争），那么可以使用轻量级锁来优化，减少传统的重量级锁使用产生的性能消耗。

> 既然多线程访问的时间是错开的（也就是没有竞争），那么为什么还要添加锁呢？
>
> 没有竞争的时候，不代表永远没有竞争，在遇到竞争的时候会锁升级，在没有竞争时候使用轻量级可以减少消耗



##### 轻量级加锁过程

- 每个线程都的栈帧都会包含一个锁记录的结构，内部可以存储锁定对象的 Mark Word
- 而Mark Word容量非常宝贵，所以对`对象`加锁之后需要把旧的信息暂存到栈帧的一个锁记录结构，解锁之后将信息恢复到MarkWord

**这里以一个代码片段演示轻量级加锁过程**

```java
    static Object obj = new Object();
    public static void method1() {
        synchronized (obj) {
            // 同步块 A
            method2();
        }
    }
    public static void method2() {
        synchronized (obj) {
            // 同步块 B
        }
    }
```

<img src="images\image-20230507225843018.png" alt="image-20230507225843018" style="zoom:150%;" />

##### 锁升级

- 轻量级锁所适应的场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。 

![image-20230507230824599](images\image-20230507230824599.png)



#### 重量级锁

这里演示对重量级锁的优化：自旋

![image-20230507231048048](images\image-20230507231048048.png)

自旋失败的情况

![image-20230507231117452](images\image-20230507231117452.png)



#### 偏向锁

- 偏向锁可以说是对轻量级锁的再次优化，即在没有锁竞争的时候，只有第一次使用 CAS 将线程 ID 设置到对象的 Mark Word 头，之后发现这个线程 ID 是自己的就表示没有竞争，不用重新 CAS。

> 在同一个对象反复获取多次锁会造成不必要的消耗，使用偏向锁后该线程后续访问会自动获得锁（不用重新CAS ）
>
> 偏向锁：为什么同一个线程会反复获取相同多次锁？
>
> 答：由于cpu时间片分配，而该线程执行效率比较高，在有效时间片段只能反复执行

**但是偏向锁会带来一些问题**

1. 撤销偏向需要将持锁线程升级为轻量级锁，这个过程中所有线程需要暂停（STW）
2. 访问对象的 hashCode 也会撤销偏向锁 （hashCode已被移动到栈帧）
3. 如果对象虽然被多个线程访问，但没有竞争，这时偏向了线程 T1 的对象仍有机会重新偏向 T2， 重偏向会重置对象的 Thread ID 
4. 撤销偏向和重偏向都是批量进行的，以类为单位 
5. 如果撤销偏向到达某个阈值(20)，整个类的所有对象都会变为不可偏向的
6. 可以主动使用 -XX:-UseBiasedLocking 禁用偏向锁



#### 锁粗化

多次循环进入同步块不如同步块内多次循环 另外 JVM 可能会做如下优化，把多次 append 的加锁操作粗化为一次（因为都是对同一个对象加锁， 没必要重入多次）

这里以StringBuffer判断演示

- ```java
  new StringBuffer().append("a").append("b").append("c")
  ```

append方法是会添加锁的，理论上这里会添加三次锁

但是实际锁被粗化，只添加了一次

#### 锁消除

JVM 会进行代码的逃逸分析，例如某个加锁对象是方法内局部变量，不会被其它线程所访问到，这时候 就会被即时编译器忽略掉所有同步操作。



| 线程 1                                       | 对象 Mark Word                | 线程 2 |
| -------------------------------------------- | ----------------------------- | ------ |
| 访问同步块 A，把 Mark 复制到 线程 1 的锁记录 |                               |        |
| CAS 修改 Mark 为线程 1 锁记录 地址           |                               |        |
| 成功（加锁）                                 | 00（轻量锁）线程 1 锁记录地址 |        |
| 执行同步块 A                                 | 00（轻量锁）线程 1 锁记录地址 |        |
| 访问同步块 B，把 Mark 复制到 线程 1 的锁记录 | 00（轻量锁）线程 1 锁记录地址 |        |
| CAS 修改 Mark 为线程 1 锁记录 地址           | 00（轻量锁）线程 1 锁记录地址 |        |
| 失败（发现是自己的锁）                       | 00（轻量锁）线程 1 锁记录地址 |        |
| 锁重入                                       | 00（轻量锁）线程 1 锁记录地址 |        |
| 执行同步块 B                                 | 00（轻量锁）线程 1 锁记录地址 |        |

| 同步块 B 执行完毕 | 00（轻量锁）线程 1 锁记录地址 |                                              |
| ----------------- | ----------------------------- | -------------------------------------------- |
| 同步块 A 执行完毕 | 00（轻量锁）线程 1 锁记录地址 |                                              |
| 成功（解锁）      | 01（无锁）                    |                                              |
|                   | 01（无锁）                    | 访问同步块 A，把 Mark 复制到 线程 2 的锁记录 |
|                   | 01（无锁）                    | CAS 修改 Mark 为线程 2 锁记录 地址           |
|                   | 00（轻量锁）线程 2 锁记录地址 | 成功（加锁）                                 |



## 锁

### 悲观锁 vs 乐观锁

* 悲观锁的代表是 synchronized 和 Lock 锁
  * 其核心思想是【线程只有占有了锁，才能去操作 共享变量，每次只有一个线程占锁成功，获取锁失败的线程，都得停下来等待】
  * 线程从运行到阻塞、再从阻塞到唤醒，涉及线程上下文切换，如果频繁发生，影响性能。
  * 实际上，线程在获取 synchronized 和 Lock 锁时，如果锁已被占用，都会做几次重试操作，减少阻塞的机会。
  * 最悲观的估计，得防着其它线程来修改共享变量，我上了锁你们都别想改，我改完了解开锁，你们才有机会。

* 乐观锁的代表是 AtomicInteger，使用 CAS来保证原子性
  * 其核心思想是【无需加锁，每次只有一个线程能成功修改共享变量，其它失败的线程不需要停止，不断重试直至成功】。
  * 由于线程一直运行，不需要阻塞，因此不涉及线程上下文切换。
  * 它需要多核 cpu 支持，且线程数不应超过 cpu 核数。
  * 最乐观的估计，不怕别的线程来修改共享变量，就算改了也没关系，我吃亏点再重试呗。



### 公平锁VS非公平锁

简单概括为资源分配的均匀和不均匀

**公平锁：**

- 每个线程获取锁的顺序是按照线程访问锁的先后顺序获取的，最前面的线程总是最先获取到锁。
- 公平锁会降低吞吐量，一般不用。
- 创建ReentrantLock 可值得为公平锁。
- 公平锁的公平体现
  * **已经处在阻塞队列**中的线程（不考虑超时）始终都是公平的，先进先出。
  * 公平锁是指**未处于阻塞队列**中的线程来争抢锁，如果队列不为空，则老实到队尾等待。
  * 非公平锁是指**未处于阻塞队列**中的线程来争抢锁，与队列头唤醒的线程去竞争，谁抢到算谁的。

**非公平锁：**

- 每个线程获取锁的顺序是随机的，并不会遵循先来先得的规则，所有线程会竞争获取锁。
- synchronized是非公平锁的经典代表。
- ReentrantLock 默认是非公平锁，当然在创建 ReentrantLock 时，可以手动指定其为公平锁，但 synchronized 只能为非公平锁。



### Synchronized和Lock

Lock： 是Java中的接口，可重入锁、悲观锁、独占锁、互斥锁、同步锁。

synchronized是Java中的关键字：用来修饰方法、对象实例。属于独占锁、悲观锁、 可重入锁。非公平锁。





### 锁类型一览表

| 锁       | 代表                                                         |
| -------- | ------------------------------------------------------------ |
| 乐观锁   | CAS                                                          |
| 悲观锁   | synchronized、vector、hashtable                              |
| 自旋锁   | CAS                                                          |
| 可重入锁 | synchronized、Reentrantlock、Lock                            |
| 读写锁   | ReentrantReadWriteLock，CopyOnWriteArrayList、CopyOnWriteArraySe |
| 公平锁   | Reentrantlock(true)                                          |
| 非公平锁 | synchronized、reentrantlock(false)锁                         |
| 共享锁   | ReentrantReadWriteLock中读锁                                 |
| 独占锁   | synchronized、vector、hashtable、ReentrantReadWriteLock中写锁 |

| 重量级锁 | synchronized       |
| -------- | ------------------ |
| 轻量级锁 | 锁优化技术         |
| 偏向锁   | 锁优化技术         |
| 分段锁   | concurrentHashMap  |
| 互斥锁   | synchronized       |
| 同步锁   | synchronized       |
| 死锁     | 相互请求对方的资源 |
| 锁粗化   | 锁优化技术         |
| 锁消除   | 锁优化技术         |



















