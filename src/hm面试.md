# 集合

## ArrayList

1) 新的JDKArrayList() 默认会使用长度为零的数组，旧的默认长度为10
2) ArrayList(int initialCapacity) 会使用指定容量的数组
3) public ArrayList(Collection<? extends E> c) 会使用 传入集合的长度c 的大小作为数组容量
4) **add(Object o) 首次扩容为 10，再次扩容为上次容量的 1.5 倍，如1.5为小数则使用位移>> ** 15/2+15
5) addAll(Collection c) 没有元素时，扩容为 Math.max(10, 实际元素个数)，有元素时为 Math.max(原容量 1.5 倍, 实际元素个数)

## Iterator 

​	iterator有2中策略Fail-Fast 与 Fail-Safe	

- ArrayList 是 fail-fast 的典型代表，遍历的同时不能修改，尽快失败   会记录当前长度expectedModCount和开始时长度 modCount

  每一次next会调用checkForCommondification()判断 if(modCount != expectedModCount)throw new ConcurrentModification

- CopyOnWriteArrayList 是 fail-safe 的典型代表，它相当于线程安全的ArrayList。遍历的同时可以修改，原理是读写分离 会在遍历时新建snapshot数组，每次添加时会复制一份数组，添加的和遍历的数组不是同一个



## LinkList 和ArrayList

​	linkList                                                       arraylsit

1. 基于双向链表，无需连续内存        	 基于数组，需要连续内存
2. 随机访问慢（要沿着链表遍历）         随机访问快（指根据下标访问）
3. 头尾插入删除性能高                            尾部插入、删除性能可以，其它部分插入、删除都会移动数据，因此性能会低
4. 占用内存多                                            可以利用 cpu 缓存，局部性原理



- linkList和ArrayList区别为   是否实现了一个RandomAccess接口，实现则直接get索引，反之调用Iterator 的list.iterator的next获取下一个元素
- arrayList头部增删慢，应为需要复制移动元素，但尾部增删快，可以直接定位到最后一个索引；头中尾查询都快可以根据索引
- linkList头尾增删快，查询快，中间都慢，因为需要next一步步找，linkList占用内存大，因为是有Node对象，node又分为item元素，next下一个元素地址，prev上一个元素 。总结arrayList整体优秀

## HashMap

### **基本结构**

* 1.7 数组 + 链表
* 1.8 数组 + （链表 | 红黑树）引入红黑树以解决链表线性长度过长查找的效率问题

**储存 **计算出数据的原始哈希值，和二次计算哈希值 (函数扰动)，使用二次哈希值对当前数组长度进行按位与计算，计算出下标

**查找** 计算数据的值后，使用二次哈希值 (函数扰动) 对当前数组哈希容量进行按位与运算，计算出下标，在下标或链表中查找

**扩容 **数据超过长度的4/3   0.75 或者链表长度超过8

**链表的问题** 二个数据可能有相同的哈希 在过多的数据下，计算的相同的下标过多，需要储存在同一个链表，链表的数据过多需要多次比对，效率过低。解决办法可以有缩减链表长度——扩容长度，因为需要重新与长度计算下表。但仍然有相同下标的可能。或者使用红黑树



### 1.8优化

| 不同                       | JDK 1.7                                                      | JDK 1.8                                                      |
| -------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 存储结构                   | 数组 + 链表                                                  | 数组 + 链表 / 红黑树                                         |
| 初始化方 式                | 单独函数： inflateTable()                                    | 直接集成到了扩容函数 resize() 中                             |
| hash值 计算方式            | 扰动处理 = 9次扰动 = 4次位运 算 + 5次异或运算                | 扰动处理 = 2次扰动 = 1次位运算 + 1次异 或运算                |
| 存放数据 的规则            | 无冲突时，存放数组；冲突 时，存放链表                        | 无冲突时，存放数组；冲突 & 链表长度 < 8：存放单链表；冲突 & 链表长度 > 8： 树化并存放红黑树 |
| 插入数据 方式              | 头插法（先讲原位置的数据移 到后1位，再插入数据到该位 置）    | 尾插法（直接插入到链表尾部/红黑树）                          |
| 扩容后存 储位置的 计算方式 | 全部按照原来方法进行计算 （即hashCode ->> 扰动函数 - >> (h&length-1)） | 按照扩容后的规律计算（即扩容后的位置 =原位置 or 原位置 + 旧容量） |



### **树化意义**

**树化** 在链表长度超过8**并且数组长度超过64**时会进行红黑树转化。实际上来链表长度超过8的可能非常低， 如数组长度不超过64但链表长度已经为8，此时添加元素只会扩容数组。

*  树化应当是偶然情况，是保底策略
* hash 表的查找，更新的时间复杂度是 `O(1)`，而红黑树的查找，更新的时间复杂度是 `O(log_2⁡n)`，TreeNode 占用空间也比普通 Node 的大，如非必要，尽量还是使用链表
* hash 值如果足够随机，则在 hash 表内按泊松分布，在负载因子 0.75 的情况下，长度超过 8 的链表出现概率是 0.00000006，树化阈值选择 8 就是为了让树化几率足够小

**TreeNode和Node**

- TreeNode是Node的子类，也就是说TreeNode含有Node的所有属性；
- Node是一个含有next属性的单向列表，TreeNode是一个含有next（继承自Node）、prev属性的双向链表，同时TreeNode还是一个含有left、right、parent属性的二叉树
- 同时TreeNode还是一个含有boolean red属性的红黑树

**树化阈值** 链表使用的Node,红黑树使用的时TreeNode，它比Node更加消耗资源。在链表过短的情况下进行树化性能反而不如链表

**退化规则**

* 情况1：在扩容时如果拆分树时，树元素个数 <= 6 则会退化链表
* 情况2：remove 树节点时，在移除之前检查、若 root、root.left、root.right、root.left.left 有一个为 null ，也会退化为链表



### **索引计算方法**

* 首先，计算对象的 hashCode()、再进行调用 HashMap 的 hash() 方法进行二次哈希、最后 & (capacity – 1) 得到索引

**二次哈希**

不同的哈希码算出相同的下标Index，就会导致哈希碰撞，一旦发生哈希碰撞，HashMap的查找效率就会从O(1)退化成O(n)或者O(logn)。所以，一个好的哈希函数应该要尽可能的分散，否则就会影响到HashMap的效率。

二次哈希就时为了提高HashMap的效率，综合高位数据。让哈希分布更为均匀，减小链表的长度。可能有些值的哈希计算出的下标集在某一个字段范围，可使用二次哈希进行一个扰动分散

1.8的二次哈希为(key.hashCode()) ^ (h >>> 16)、即先拿取原始哈希再右移16位，也就是高16位在与原始哈希进行异或运算

**数组容量为何是 2 的 n 次幂**

1. 计算索引时效率更高：如果是 2 的 n 次幂可以使用位与运算代替取模，因为求模类似与除法，按位与运算效率更高。
2. 扩容时重新计算索引效率更高： hash & oldCap == 0 的元素留在原来位置 ，否则新位置 = 旧位置 + oldCap
3. 二次 hash 是为了配合 容量是 2 的 n 次幂 这一设计前提，如果 hash 表的容量不是 2 的 n 次幂，则不必二次 hash
4. 容量是 2 的 n 次幂这一设计计算索引效率更好，但 hash 的分散性就不好，需要二次 hash 来作为补偿，没有采用这一设计的典型例子是 Hashtable,
5. 在指定数组长度时传入指定大小最好为2的n次方，反之HashMap也会转化多了一部操作；

二次哈希是为了弥补2的n次幂的分布不均匀，2的n次幂是为了提高HashMap的效率，每次放取都需计算下标，所以计算效率也尤为重要

**put 流程**

1. HashMap 是懒惰创建数组的，首次使用才创建数组
2. 计算索引（桶下标）
3. 如果桶下标还没人占用，创建 Node 占位返回
4. 如果桶下标已经有人占用
   1. 已经是 TreeNode 走红黑树的添加或更新逻辑
   2. 是普通 Node，走链表的添加或更新逻辑，如果链表长度超过树化阈值，走树化逻辑
5. 返回前检查容量是否超过阈值，一旦超过进行扩容，添加数据后在进行扩容

**1.7 与 1.8 的区别**

1. 链表插入节点时，1.7 是头插法，1.8 是尾插法
2. 1.7 是大于等于阈值且没有空位时才扩容，而 1.8 是大于阈值就扩容
3. 1.8 在扩容计算 Node 索引时，会优化  把哈希值与旧的数组容量做一个按位与，如是0不用动位置,新的位置为旧的索引加旧容量

**扩容（加载）因子为何默认是 0.75f**

1. 在空间占用与查询时间之间取得较好的权衡
2. 大于这个值，空间节省了，但链表就会比较长影响性能
3. 小于这个值，冲突减少了，但扩容就会更频繁，空间占用也更多



### 并发问题

在并发的情况下可能会出现数据错乱的问题，即t2线程覆盖t1的数据

扩容死链（存在d1.7 ）即在多线程数组扩容移动链表的情况下发送链表死循环

- e 和 next 都是局部变量，用来指向当前节点和下一个节点

* 线程1的临时变量 e 和 next 刚引用了这俩节点，还未来得及移动节点，发生了线程切换，由线程2 完成扩容和迁移
* 线程2 扩容完成，由于头插法，链表顺序颠倒。但线程1 的临时变量 e 和 next 还引用了这俩节点，还要再来一遍迁移

第一次循环

* 循环接着线程切换前运行，注意此时 e 指向的是节点 a，next 指向的是节点 b
* e 头插 a 节点

第二次循环

* next 指向了节点 a
* e 头插节点 b
* 当循环结束时，e 指向 next 也就是节点 a

第三次循环

* next 指向了 null
* e 头插节点 a，**a 的 next 指向了 b**（之前 a.next 一直是 null），b 的 next 指向 a，死链已成
* 当循环结束时，e 指向 next 也就是 null，因此第四次循环时会正常退出



### Key的设计

1. HashMap 的 key 可以为 null，但 Map 的其他实现则不然
2. 作为 key 的对象，必须实现 hashCode 和 equals，并且 key 的内容不能修改（不可变）
3. 重写hashCode是为了key更好的分布性，重写equals 是为了防止在相同的hash码需要进一步进行比对
4. hash相同但equals不一定相同，equals相同那么hash一定相同
5. key 的 hashCode 应该有良好的散列性  即分布在不同的数组下标

如果 key 可变，例如修改了 age 会导致再次查询时查询不到

**String 对象的 hashCode() 设计**

* 目标是达到较为均匀的散列效果，每个字符串的 hashCode 足够独特
* 字符串中的每个字符都可以表现为一个数字，称为 $S_i$，其中 i 的范围是 0 ~ n - 1 
* 散列公式为： $S_0∗31^{(n-1)}+ S_1∗31^{(n-2)}+ … S_i ∗ 31^{(n-1-i)}+ …S_{(n-1)}∗31^0$
* 为什么每一次乘以31，因为31 代入公式有较好的散列特性，并且 31 * h 可以被优化为 
  * 即 $32 ∗h -h $
  * 即 $2^5  ∗h -h$
  * 即 $h≪5  -h$

### 总结

HashMap底层采用数组+链表/红黑树来存储键值对，会根据Key的哈希码来计算键值对落在数组的哪个下标。如果不同的哈希码算出相同的下标，就会导致哈希碰撞，影响HashMap的性能。HashMap要做的，就是尽量避免哈希碰撞，所以加入了扰动函数。扰动函数会将哈希码的高16位与低16位做异或运算，让高位也参与到下标的计算过程中来，从而影响最终下标的计算结果，减少哈希碰撞的概率。至于为啥是16位，这是因为哪些位会参与到下标的计算，取决于HashMap数组的长度，在绝大部分情况下，数组的长度都不会超过65536，16位是一个折中的数字。



# 多线程

**六种状态及转换**

![image-20210831090722658](E:\java\pdf资料\面试\day02-并发篇\讲义\img\image-20210831090722658.png)

分别是

* 新建
  * 当一个线程对象被创建，但还未调用 start 方法时处于**新建**状态
  * 此时未与操作系统底层线程关联
* 可运行
  * 调用了 start 方法，就会由**新建**进入**可运行**
  * 此时与底层线程关联，由操作系统调度执行
* 终结
  * 线程内代码已经执行完毕，由**可运行**进入**终结**
  * 此时会取消与底层线程关联
* 阻塞
  * 当获取锁失败后，由**可运行**进入 Monitor 的阻塞队列**阻塞**，此时不占用 cpu 时间
  * 当持锁线程释放锁时，会按照一定规则唤醒阻塞队列中的**阻塞**线程，唤醒后的线程进入**可运行**状态
* 等待
  * 当获取锁成功后，但由于条件不满足，调用了 wait() 方法，此时从**可运行**状态释放锁进入 Monitor 等待集合**等待**，同样不占用 cpu 时间
  * 当其它持锁线程调用 notify() 或 notifyAll() 方法，会按照一定规则唤醒等待集合中的**等待**线程，恢复为**可运行**状态
* 有时限等待
  * 当获取锁成功后，但由于条件不满足，调用了 wait(long) 方法，此时从**可运行**状态释放锁进入 Monitor 等待集合进行**有时限等待**，同样不占用 cpu 时间
  * 当其它持锁线程调用 notify() 或 notifyAll() 方法，会按照一定规则唤醒等待集合中的**有时限等待**线程，恢复为**可运行**状态，并重新去竞争锁
  * 如果等待超时，也会从**有时限等待**状态恢复为**可运行**状态，并重新去竞争锁
  * 还有一种情况是调用 sleep(long) 方法也会从**可运行**状态进入**有时限等待**状态，但与 Monitor 无关，不需要主动唤醒，超时时间到自然恢复为**可运行**状态

> ***其它情况（只需了解）***
>
> * 可以用 interrupt() 方法打断**等待**、**有时限等待**的线程，让它们恢复为**可运行**状态
> * park，unpark 等方法也可以让线程等待和唤醒

**五种状态**

五种状态的说法来自于操作系统层面的划分

![image-20210831092652602](E:\java\pdf资料\面试\day02-并发篇\讲义\img\image-20210831092652602.png)

* 运行态：分到 cpu 时间，能真正执行线程内代码的
* 就绪态：有资格分到 cpu 时间，但还未轮到它的
* 阻塞态：没资格分到 cpu 时间的
  * 涵盖了 java 状态中提到的**阻塞**、**等待**、**有时限等待**
  * 多出了阻塞 I/O，指线程在调用阻塞 I/O 时，实际活由 I/O 设备完成，此时线程无事可做，只能干等
* 新建与终结态：与 java 中同名状态类似，不再啰嗦



##  线程池

**要求**

* 掌握线程池的 7 大核心参数

**七大参数**

1. corePoolSize 核心线程数目 - 池中会保留的最多线程数
2. maximumPoolSize 最大线程数目 - 核心线程+救急线程的最大数目
3. keepAliveTime 生存时间 - 救急线程的生存时间，生存时间内没有新任务，此线程资源会释放
4. unit 时间单位 - 救急线程的生存时间单位，如秒、毫秒等
5. workQueue - 当没有空闲核心线程时，新来任务会加入到此队列排队，队列满会创建救急线程执行任务
6. threadFactory 线程工厂 - 可以定制线程对象的创建，例如设置线程名字、是否是守护线程等
7. handler 拒绝策略 - 当所有线程都在繁忙，workQueue 也放满时，会触发拒绝策略
   1. 抛异常 java.util.concurrent.ThreadPoolExecutor.AbortPolicy
   2. 由调用者执行任务 java.util.concurrent.ThreadPoolExecutor.CallerRunsPolicy
   3. 丢弃任务 java.util.concurrent.ThreadPoolExecutor.DiscardPolicy
   4. 丢弃最早排队任务 java.util.concurrent.ThreadPoolExecutor.DiscardOldestPolicy

![image-20210831093204388](E:\java\pdf资料\面试\day02-并发篇\讲义\img\image-20210831093204388.png)

> ***代码说明***
>
> day02.TestThreadPoolExecutor 以较为形象的方式演示了线程池的核心组成



##  wait vs sleep

**要求**

* 能够说出二者区别

**一个共同点，三个不同点**

共同点

* wait() ，wait(long) 和 sleep(long) 的效果都是让当前线程暂时放弃 CPU 的使用权，进入阻塞状态

不同点

* 方法归属不同
  * sleep(long) 是 Thread 的静态方法
  * 而 wait()，wait(long) 都是 Object 的成员方法，每个对象都有

* 醒来时机不同
  * 执行 sleep(long) 和 wait(long) 的线程都会在等待相应毫秒后醒来
  * wait(long) 和 wait() 还可以被 notify 唤醒，wait() 如果不唤醒就一直等下去
  * 它们都可以被打断唤醒

* 锁特性不同（重点）
  * wait 方法的调用必须先获取 wait 对象的锁，而 sleep 则无此限制
  * wait 方法执行后会释放对象锁，允许其它线程获得该对象锁（我放弃 cpu，但你们还可以用）
  * 而 sleep 如果在 synchronized 代码块中执行，并不会释放对象锁（我放弃 cpu，你们也用不了）



##  lock vs synchronized

**要求**

* 掌握 lock 与 synchronized 的区别
* 理解 ReentrantLock 的公平、非公平锁
* 理解 ReentrantLock 中的条件变量

**三个层面**

不同点

* 语法层面
  * synchronized 是关键字，源码在 jvm 中，用 c++ 语言实现
  * Lock 是接口，源码由 jdk 提供，用 java 语言实现
  * 使用 synchronized 时，退出同步代码块锁会自动释放，而使用 Lock 时，需要手动调用 unlock 方法释放锁
* 功能层面
  * 二者均属于悲观锁、都具备基本的互斥、同步、锁重入功能
  * Lock 提供了许多 synchronized 不具备的功能，例如获取等待状态、公平锁、可打断、可超时、多条件变量
  * Lock 有适合不同场景的实现，如 ReentrantLock， ReentrantReadWriteLock
* 性能层面
  * 在没有竞争时，synchronized 做了很多优化，如偏向锁、轻量级锁，性能不赖
  * 在使用synchronized锁时可适当扩大区间，重复多次加锁消耗性能
  * 在竞争激烈时，Lock 的实现通常会提供更好的性能

**公平锁**

* 公平锁的公平体现
  * **已经处在阻塞队列**中的线程（不考虑超时）始终都是公平的，先进先出
  * 公平锁是指**未处于阻塞队列**中的线程来争抢锁，如果队列不为空，则老实到队尾等待
  * 非公平锁是指**未处于阻塞队列**中的线程来争抢锁，与队列头唤醒的线程去竞争，谁抢到算谁的
* 公平锁会降低吞吐量，一般不用

**条件变量**

* ReentrantLock 中的条件变量功能类似于普通 synchronized 的 wait，notify，用在当线程获得锁后，发现条件不满足时，临时等待的链表结构
* 与 synchronized 的等待集合不同之处在于，ReentrantLock 中的条件变量可以有多个，可以实现更精细的等待、唤醒控制



## volatile

volatile主要作用有**可见性**和**有序性**

强制将修改后的值刷新到主内存中来保持内存的可见性,让一个线程对共享变量的修改对另一个线程可见。

过 CPU内存屏障禁止编译器指令性重排来保证并发操作的有序性

在 Java 中，Java 并没有直接实现 CAS（Compare And Swap），CAS 相关的实现是通过 C++ 内联汇编的形式实现的。

指令重排序，所谓重排序，就是指令的编写顺序和执行顺序不一致，在多线程环 境下导致可见性问题。指令重排序本质上是一种性能优化的手段，它来自于几个 方面。

**要求**

* 掌握线程安全要考虑的三个问题
* 掌握 volatile 能解决哪些问题

**原子性**

* 起因：多线程下，不同线程的**指令发生了交错**导致的共享变量的读写混乱
* 解决：用悲观锁或乐观锁解决，volatile 并不能解决原子性

**可见性**

* 起因：由于**编译器优化、或缓存优化、或 CPU 指令重排序优化**导致的对共享变量所做的修改另外的线程看不到
* 解决：用 volatile 修饰共享变量，能够防止编译器等优化发生，让一个线程对共享变量的修改对另一个线程可见

**有序性**

* 起因：由于**编译器优化、或缓存优化、或 CPU 指令重排序优化**导致指令的实际执行顺序与编写顺序不一致
* 解决：用 volatile 修饰共享变量会在读、写共享变量时加入不同的屏障，阻止其他读写操作越过屏障，从而达到阻止重排序的效果
* 注意：
  * **volatile 变量写**加的屏障是阻止上方其它写操作越过屏障排到 **volatile 变量写**之下
  * **volatile 变量读**加的屏障是阻止下方其它读操作越过屏障排到 **volatile 变量读**之上
  * volatile 读写加入的屏障只能防止同一线程内的指令重排



## 悲观锁 vs 乐观锁

**对比悲观锁与乐观锁**

* 悲观锁的代表是 synchronized 和 Lock 锁
  * 其核心思想是【线程只有占有了锁，才能去操作共享变量，每次只有一个线程占锁成功，获取锁失败的线程，都得停下来等待】
  * 线程从运行到阻塞、再从阻塞到唤醒，涉及线程上下文切换，如果频繁发生，影响性能
  * 实际上，线程在获取 `synchronized` 和 `Lock` 锁时，如果锁已被占用，都会做几次重试操作，减少阻塞的机会
* 乐观锁的代表是 `AtomicInteger`，使用 `CAS`+`volatitle` 来保证原子性
  * 其核心思想是【无需加锁，每次只有一个线程能成功修改共享变量，其它失败的线程不需要停止，不断重试直至成功】
  * 由于线程一直运行，不需要阻塞，因此不涉及线程上下文切换
  * 它需要多核 cpu 支持，且线程数不应超过 cpu 核数









































